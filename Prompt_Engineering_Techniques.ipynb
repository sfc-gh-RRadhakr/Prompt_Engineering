{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee6876b5-2675-4590-878f-d715a87bba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install python-dotenv\n",
    "#pip install \"openai<1\" to install the older version of the OpenAI API we will upgrade later\n",
    "import openai \n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313dbf36-8b4b-4021-87cb-f239d39e4077",
   "metadata": {},
   "source": [
    "###### **Secure your API Key**: To safeguard your OpenAI API key, it's recommended to keep it in an environment variable within your .env file. This way, the key remains hidden and not plainly visible within your Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5918d3bf-c917-49ea-99b9-814268f06b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting  OPENAI_API_KEY  from the .env file \n",
    "config = dotenv_values(\".env\")\n",
    "openai.api_key = config[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac900b93-b389-4fa4-b871-38e747dd3f8a",
   "metadata": {},
   "source": [
    "###### **Helper Function** To call the function get_completion() to reuse the call to the openaai api endpoint\n",
    "example :\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5f4ed1-e2d0-461c-9b88-ec672a90987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' What is temperature=0 ?\n",
    "Higher values like 0.8 will make the output more random, \n",
    "while lower values like 0.2 will make it more focused and deterministic.\n",
    "Deterministic Output: With temperature set to 0, the model's output \n",
    "becomes completely deterministic. This means that for a given input or prompt, the model \n",
    "will always produce the same output, no matter how many times you generate a response. \n",
    "'''\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "'''In order to use the OpenAI library version 1.0.0, here is the code that you would use instead for the get_completion function:\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77170feb-78e9-4fed-b1ce-4c52b6b76ef9",
   "metadata": {},
   "source": [
    "#### Prompting Principles\n",
    "###### **Principle 1** - Articulate Precise and Detailed Directives: Ensure that your instructions are articulated with clarity and precision, leaving no room for ambiguity.\n",
    "###### **Principle 2** - Allocate Adequate Processing Time: Allow sufficient time for the model to process and 'ponder' over the given instructions for optimal outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3997203-8683-4c26-b5e5-5603f6cc6666",
   "metadata": {},
   "source": [
    "###### Applying Principle 1   Delimiters can be anything like: ```, \"\"\", < >, <tag> </tag>, :\n",
    "###### Applying Principle 1   Ask for strucutred output LIST, JSON HTML:\n",
    "###### Applying Principle 1   Check the answers with the condition to make sure it is not making wild assumptions :\n",
    "###### Applying Principle 1   Few-shot promting, providing the model with few example so it can understand the task :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef50d9cc-ef04-4e94-ae16-48d8008ef468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake's architecture combines elements of both shared-disk and shared-nothing database architectures, utilizing a central data repository for persisted data that is accessible from all compute nodes, while also processing queries using MPP compute clusters where each node stores a portion of the data set locally, providing the simplicity of a shared-disk architecture with the performance and scalability advantages of a shared-nothing architecture.\n"
     ]
    }
   ],
   "source": [
    "# Using clear Delimiters in the text\n",
    "text = f\"\"\"\n",
    "Snowflake’s architecture is a hybrid of traditional \\\n",
    "shared-disk and shared-nothing database architectures. \n",
    "Similar to shared-disk architectures, Snowflake uses a \\\n",
    "central data repository for persisted data that is accessible from all compute nodes in the platform.\\\n",
    "But similar to shared-nothing architectures, Snowflake processes queries using MPP (massively parallel processing) \\\n",
    "compute clusters where each node in the cluster stores a portion of the entire data set locally. This approach offers \\\n",
    "the data management simplicity \\\n",
    "of a shared-disk architecture, but with the performance and scale-out benefits of a shared-nothing architecture.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22564585-6396-4166-a5da-b78420155cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"ISBN\": \"978-0486203815\",\n",
      "    \"title\": \"The Interpretation of Dreams\",\n",
      "    \"author\": \"Sigmund Freud\",\n",
      "    \"year\": 1899\n",
      "  },\n",
      "  {\n",
      "    \"ISBN\": \"978-0486417818\",\n",
      "    \"title\": \"The Principles of Psychology\",\n",
      "    \"author\": \"William James\",\n",
      "    \"year\": 1890\n",
      "  },\n",
      "  {\n",
      "    \"ISBN\": \"978-0486206212\",\n",
      "    \"title\": \"Psychopathology of Everyday Life\",\n",
      "    \"author\": \"Sigmund Freud\",\n",
      "    \"year\": 1901\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Displaying in strcutured output\n",
    "prompt = f\"\"\"\n",
    "Generate a list of three psychology books  from 1800s along \\ \n",
    "with their authors and  first year of pulication  . \n",
    "Generate t them in JSON format with the following keys: \n",
    "ISBN, title, author, year.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3c8188-7c24-464f-827b-971e79f974d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**STEP 1 - Prepare your data in a compatible format**\n",
      "- Ensure your data is clean and structured\n",
      "- Convert your data into a compatible format such as CSV, JSON, Parquet, or Avro\n",
      "\n",
      "**STEP 2 - Store your data in a cloud storage solution**\n",
      "- Choose a cloud storage solution like Amazon S3, Google Cloud Storage, or Azure Blob Storage\n",
      "- Upload your data files to the chosen cloud storage location\n",
      "\n",
      "**STEP 3 - Set up an external stage in Snowflake**\n",
      "- Create an external stage in Snowflake to link to the cloud storage location where your data is stored\n",
      "- Configure the stage to specify the cloud storage provider, location, and credentials\n",
      "\n",
      "**STEP 4 - Define a file format in Snowflake**\n",
      "- Define a file format in Snowflake that matches the format of your data files\n",
      "- Specify the file format options such as field delimiter, record delimiter, and data type mappings\n",
      "\n",
      "**STEP 5 - Create a database and schema in Snowflake**\n",
      "- Create a database in Snowflake to hold your data\n",
      "- Create a schema within the database to organize your tables\n",
      "\n",
      "**STEP 6 - Create a table with a schema matching your data**\n",
      "- Create a table in Snowflake with a schema that matches the structure of your data\n",
      "- Define the columns, data types, and any constraints for the table\n",
      "\n",
      "**STEP 7 - Use the COPY INTO command to transfer data**\n",
      "- Use the COPY INTO command in Snowflake to transfer data from the external stage to your Snowflake table\n",
      "- Specify the file format, stage, and table in the COPY INTO command\n",
      "- Optionally, specify handling options such as error handling and data transformation\n",
      "\n",
      "**STEP 8 - Validate the loaded data**\n",
      "- Execute queries on the loaded data to validate its correctness and completeness\n",
      "- Check for any discrepancies or errors in the loaded data\n",
      "- Make any necessary adjustments or corrections to ensure a successful data transfer into Snowflake's data warehousing environment.\n"
     ]
    }
   ],
   "source": [
    "# Checking for conditions \n",
    "\n",
    "text=f\"\"\"Loading data into Snowflake involves several key steps.\\\n",
    "First, prepare your data in a compatible format, such as CSV, JSON, \\\n",
    "Parquet, or Avro, and ensure it's clean and structured. Store your data in a \\\n",
    "cloud storage solution like Amazon S3, Google Cloud Storage, or Azure Blob Storage, \\\n",
    "and set up an external stage in Snowflake to link to this location. Define a file format in \\\n",
    "Snowflake to interpret the data files correctly. Create a database and schema within Snowflake, \\\n",
    "followed by a table with a schema matching your data. Use the COPY INTO command to transfer data from the stage \\\n",
    "to your Snowflake table, specifying the file format and handling options. Finally, validate the loaded data by executing \\\n",
    "queries and checking for any discrepancies to ensure a successful data transfer into Snowflake's cloud-based data warehousing \\\n",
    "environment.\"\"\"\n",
    "prompt =f\"\"\" Based on the instruction provided in the text to load data into snowflake, provide the step by step instruction in the following format:\n",
    "STEP 1 -\n",
    "STEP 2 -\n",
    "STEP N -\n",
    "\n",
    "Make each step heading in bold\n",
    "if the instruction provided in the text doesn't contain sequence of instructions then write \"No instruction provided\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91a82b25-d1dc-4df5-869d-e699947c26af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Expert>: A multi-cloud platform refers to the use of multiple cloud computing services from different providers, such as AWS, Azure, and Google Cloud, to meet an organization's needs. It allows businesses to leverage the strengths and capabilities of different cloud providers, avoiding vendor lock-in and increasing flexibility and resilience. With a multi-cloud approach, organizations can distribute workloads across different clouds, optimize costs, and take advantage of specific services offered by each provider.\n"
     ]
    }
   ],
   "source": [
    "#Few-Shot Promting \n",
    "prompt=f\"\"\"Your task is to answer abour snowflake cloud platform.\n",
    "<User> :  What is Snowflake Computing?\n",
    "<Expert>:Snowflake, available on AWS, Azure, and Google Cloud,\\\n",
    "offers Data Warehouse-as-a-Service, handling vast structured or semi-structured data \\\n",
    "volumes with minimal effort. Its unique selling point isn't just being a SaaS data warehouse; \\\n",
    "it’s the specific features and efficiencies that set it apart from competitors\n",
    "<User> : what is multi-cloud platform?\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e524a5-bff6-4483-9314-195c4c19f68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
